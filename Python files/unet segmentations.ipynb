{"cells":[{"metadata":{},"cell_type":"markdown","source":"# unet implimentation in renetal vessel dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install numpy==1.16.4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\nseed=42\n\nnp.random.seed = seed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom glob import glob\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom skimage.transform import resize\nfrom keras import regularizers\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.core import Dropout, Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import backend as K\nimport tensorflow as tf\nfrom skimage.color import rgb2gray\nfrom skimage.transform import resize\nfrom skimage.io import imread\nimport numpy as np\nfrom keras.callbacks import History\nimport matplotlib.pyplot as plt\n\n\nprint('okay')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set some parameters\nheight = 64*3\nwidth = 64*3\nIMG_CHANNELS = 1\n\nseed = 42","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask=np.load(r'../input/brats-2013/npy_file_t1c/npy_file_t1c/dataset/dataset.npy',allow_pickle=True)\ndataset=np.load(r'../input/brats-2013/npy_file_t1c/npy_file_t1c/masks/mask.npy',allow_pickle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask[1].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_set=[]\n\nmask_set=[]\n\nfor i in range(1000):\n    image_set.append(cv2.resize(dataset[i],(width,height)))\n    \n    mask_set.append(cv2.resize(mask[i],(width,height)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_set=np.array(mask_set)\n\nimage_set=np.array(image_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batchsize=8\n\nprint('okay')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mean_iou(y_true, y_pred):\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        y_pred_ = tf.to_int32(y_pred > t)\n        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n        K.get_session().run(tf.local_variables_initializer())\n        with tf.control_dependencies([up_opt]):\n            score = tf.identity(score)\n        prec.append(score)\n    return K.mean(K.stack(prec), axis=0)\n\nprint('okay')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define IoU metric\ndef mean_iou(y_true, y_pred):\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        y_pred_ = tf.to_int32(y_pred > t)\n        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n        K.get_session().run(tf.local_variables_initializer())\n        with tf.control_dependencies([up_opt]):\n            score = tf.identity(score)\n        prec.append(score)\n    return K.mean(K.stack(prec), axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(y_true * y_pred, axis=[1])\n    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1])\n    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef_loss(y_true, y_pred):\n    return 1-dice_coef(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build U-Net model\ninputs = Input((height, width, IMG_CHANNELS))\ns = Lambda(lambda x: x / 255) (inputs)\n\nc1 = Conv2D(8, (3, 3), activation='elu',kernel_regularizer=regularizers.l2(0.00001),\n            kernel_initializer='he_normal', padding='same') (s)\nc1 = Dropout(rate=0.1) (c1)\nc1 = Conv2D(8, (3, 3), activation='elu',kernel_regularizer=regularizers.l2(0.00001),\n            kernel_initializer='he_normal', padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(16, (3, 3), activation='elu',kernel_regularizer=regularizers.l2(0.00001),\n            kernel_initializer='he_normal', padding='same') (p1)\nc2 = Dropout(rate=0.1) (c2)\nc2 = Conv2D(16, (3, 3), activation='elu',kernel_regularizer=regularizers.l2(0.00001),\n            kernel_initializer='he_normal', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(32, (3, 3), activation='elu',kernel_regularizer=regularizers.l2(0.00001),\n            kernel_initializer='he_normal', padding='same') (p2)\nc3 = Dropout(rate=0.2) (c3)\nc3 = Conv2D(32, (3, 3), activation='elu',kernel_regularizer=regularizers.l2(0.00001),\n            kernel_initializer='he_normal', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(64, (3, 3), activation='elu',kernel_regularizer=regularizers.l2(0.00001),\n            kernel_initializer='he_normal', padding='same') (p3)\nc4 = Dropout(rate=0.2) (c4)\nc4 = Conv2D(64, (3, 3), activation='elu',kernel_regularizer=regularizers.l2(0.00001),\n            kernel_initializer='he_normal', padding='same') (c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\nc5 = Conv2D(128, (3, 3), activation='elu', kernel_regularizer=regularizers.l2(0.00001),\n            kernel_initializer='he_normal', padding='same') (p4)\nc5 = Dropout(rate=0.3) (c5)\nc5 = Conv2D(128, (3, 3), activation='elu', kernel_regularizer=regularizers.l2(0.00001),\n            kernel_initializer='he_normal', padding='same') (c5)\n\nu6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(64, (3, 3), activation='elu',kernel_regularizer=regularizers.l2(0.00001),\n            kernel_initializer='he_normal', padding='same') (u6)\nc6 = Dropout(rate=0.2) (c6)\nc6 = Conv2D(64, (3, 3), activation='elu', kernel_regularizer=regularizers.l2(0.00001),\n            kernel_initializer='he_normal', padding='same') (c6)\n\nu7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(32, (3, 3), activation='elu',kernel_regularizer=regularizers.l2(0.0001),\n            kernel_initializer='he_normal', padding='same') (u7)\nc7 = Dropout(rate=0.2) (c7)\nc7 = Conv2D(32, (3, 3), activation='elu', kernel_regularizer=regularizers.l2(0.00001),\n            kernel_initializer='he_normal', padding='same') (c7)\n\nu8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(16, (3, 3), activation='elu',kernel_regularizer=regularizers.l2(0.00001),\n            kernel_initializer='he_normal', padding='same') (u8)\nc8 = Dropout(rate=0.1) (c8)\nc8 = Conv2D(16, (3, 3), activation='elu', kernel_regularizer=regularizers.l2(0.00001),\n            kernel_initializer='he_normal', padding='same') (c8)\n\nu9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(8, (3, 3), activation='elu', kernel_regularizer=regularizers.l2(0.00001),\n            kernel_initializer='he_normal', padding='same') (u9)\nc9 = Dropout(rate=0.1) (c9)\nc9 = Conv2D(8, (3, 3), activation='elu', kernel_regularizer=regularizers.l2(0.00001),\n            kernel_initializer='he_normal', padding='same') (c9)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\nmodel = (Model(inputs=[inputs], outputs=[outputs]))\n\n#model.summary()\n\nprint('okay')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pngs_mask[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_set[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_set.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#image_set[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_set = image_set.reshape(-1,height,width,1)\nmask_set = mask_set.reshape(-1,height,width,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#image_set=np.expand_dims(image_set,axis=3)\n#mask_set=np.expand_dims(mask_set,axis=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split train and valid\n#X_train, X_valid, X_feat_train, X_feat_valid, y_train, y_valid = train_test_split(X, X_feat, y, test_size=0.15, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalize X_feat\n#x_feat_mean = X_feat_train.mean(axis=0, keepdims=True)\n#x_feat_std = X_feat_train.std(axis=0, keepdims=True)\n#X_feat_train -= x_feat_mean\n#X_feat_train /= x_feat_std\n\n#X_feat_valid -= x_feat_mean\n#X_feat_valid /= x_feat_std","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_set.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#callbacks = [\n    #EarlyStopping(patience=5, verbose=1),\n    #ReduceLROnPlateau(patience=3, verbose=1),\n    #ModelCheckpoint('model-tgs-salt-1.h5', verbose=1, save_best_only=True, save_weights_only=True)]\n\n#results = model.fit({'img': X_train, 'feat': X_feat_train}, y_train, batch_size=16, epochs=50, callbacks=callbacks,\n                    #validation_data=({'img': X_valid, 'feat': X_feat_valid}, y_valid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=[dice_coef_loss])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output=model.fit(x=image_set, y=mask_set, batch_size=None, epochs=100, callbacks=None, validation_split=0.3, \n          validation_data=None,steps_per_epoch=700//batchsize,validation_steps=300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.evaluate({'img': X_valid, 'feat': X_feat_valid}, y_valid, verbose=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# src: https://www.kaggle.com/aglotero/another-iou-metric\n'''def iou_metric(y_true_in, y_pred_in, print_table=False):\n    labels = y_true_in\n    y_pred = y_pred_in\n    \n    true_objects = 2\n    pred_objects = 2\n\n    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n\n    # Compute areas (needed for finding the union between all objects)\n    area_true = np.histogram(labels, bins = true_objects)[0]\n    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n    area_true = np.expand_dims(area_true, -1)\n    area_pred = np.expand_dims(area_pred, 0)\n\n    # Compute union\n    union = area_true + area_pred - intersection\n\n    # Exclude background from the analysis\n    intersection = intersection[1:,1:]\n    union = union[1:,1:]\n    union[union == 0] = 1e-9\n\n    # Compute the intersection over union\n    iou = intersection / union\n\n    # Precision helper function\n    def precision_at(threshold, iou):\n        matches = iou > threshold\n        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n        return tp, fp, fn\n\n    # Loop over IoU thresholds\n    prec = []\n    if print_table:\n        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n    for t in np.arange(0.5, 1.0, 0.05):\n        tp, fp, fn = precision_at(t, iou)\n        if (tp + fp + fn) > 0:\n            p = tp / (tp + fp + fn)\n        else:\n            p = 0\n        if print_table:\n            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n        prec.append(p)\n    \n    if print_table:\n        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n    return np.mean(prec)\n\ndef iou_metric_batch(y_true_in, y_pred_in):\n    batch_size = y_true_in.shape[0]\n    metric = []\n    for batch in range(batch_size):\n        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n        metric.append(value)\n    return np.mean(metric)\nthres = np.linspace(0.25, 0.75, 20)\nthres_ioc = [iou_metric_batch(y_valid, np.int32(preds_val > t)) for t in tqdm_notebook(thres)]'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('training complete')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights('u_net_weights.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport random\n\nnum=random.randint(0,100)\n\n#name=r'../input/mri/mri/image/renamedimage/id_' + str(num) + '.png'\n\nnp.seterr(divide='ignore', invalid='ignore')\n\n#test_img = cv2.imread(name,0)\n\ntest_img=image_set[num]\n\ntest_img = test_img/np.max(test_img)\n\n#test_image= image.img_to_array(test_image)\n\ntest_img = resize(test_img,(height,width,1))\n\ntest_img.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_img = np.expand_dims(test_img, axis=0)\ntest_img.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = model.predict(test_img,batch_size=None, verbose=0, steps=1)\n\nresults.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\n\nresults=np.reshape(results,(height,width))\n\nresults.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_image=np.reshape(test_img,(height,width))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#name_actual_mask=r'../input/mri/mri/mask/markedrenamed/id_' + str(num) + '.png'\n\n#actual_mask=cv2.imread(name_actual_mask)\n\nactual_mask=mask_set[num]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict on train, val and test\n'''preds_train = model.predict({'img': X_train, 'feat': X_feat_train}, verbose=1)\npreds_val = model.predict({'img': X_valid, 'feat': X_feat_valid}, verbose=1)\npreds_test = model.predict({'img': X_test, 'feat': X_feat_test}, verbose=1)\n\n# Threshold predictions\npreds_train_t = (preds_train > 0.5).astype(np.uint8)\npreds_val_t = (preds_val > 0.5).astype(np.uint8)\npreds_test_t = (preds_test > 0.5).astype(np.uint8)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"actual_mask.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"op=results>0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(num)\n\nplt.imshow(np.reshape(test_img,(height,width)),cmap='seismic')\nplt.title('actual image')\nplt.show()\n\nplt.imshow(op,cmap='seismic')\nplt.title('predicted mask')\nplt.show()\n\nplt.imshow(np.reshape(actual_mask,(height,width)),cmap='seismic')\nplt.title('actual mask')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}