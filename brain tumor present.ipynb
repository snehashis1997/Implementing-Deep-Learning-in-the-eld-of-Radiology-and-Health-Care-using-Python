{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.losses import binary_crossentropy\nimport numpy as np\nfrom glob import glob\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.metrics import confusion_matrix\nimport cv2\nimport copy","execution_count":159,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"batchsize = 32*4\nseed = 0","execution_count":160,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"present=r'../input/brain-mri-images-for-brain-tumor-detection/brain-mri-images-for-brain-tumor-detection/yes/*.*'\nnotpresent=r'../input/brain-mri-images-for-brain-tumor-detection/brain-mri-images-for-brain-tumor-detection/no/*.*'","execution_count":161,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset=[]\n\ny_true=[]\n\nfrom skimage.transform import resize\n\npngs_p=glob(present)\n\npngs_n=glob(notpresent)\n\nfor i in range(len(pngs_p)):\n    \n    img=cv2.imread(pngs_p[i],0)\n    img=resize(img,(64,64))\n    dataset.append(img)\n    y_true.append(int(1))\n    \nfor i in range(len(pngs_n)):\n    \n    img=cv2.imread(pngs_n[i],0)\n    img=resize(img,(64,64))\n    dataset.append(img)\n    y_true.append(int(0))","execution_count":162,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(dataset)","execution_count":177,"outputs":[{"output_type":"execute_result","execution_count":177,"data":{"text/plain":"253"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(y_true)","execution_count":176,"outputs":[{"output_type":"execute_result","execution_count":176,"data":{"text/plain":"253"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def CNN_neural():\n    # Indicates that our model is built using Sequential layers\n    model=Sequential()\n    \n    # First, we add multiples convolution layers to find patterns\n    model.add(Conv2D(filters=32,kernel_size=(3,3),strides=1,activation='relu',input_shape=(64,64,1)))\n    # Next, we add Pooling layer to reduce the size and find the occurence of feature in the convolution set\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    # Scales the outputs of previous layers\n    model.add(BatchNormalization(axis=-1))\n    \n    # We repeat the same to create a slightly complex model\n    model.add(Conv2D(filters=32,kernel_size=(3,3),strides=1,activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(BatchNormalization(axis=-1))\n    \n    model.add(Conv2D(filters=32,kernel_size=(3,3),strides=1,activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(BatchNormalization(axis=-1))\n    \n    # To prevent overfitting\n    model.add(Dropout(rate=0.25))\n    \n    # Now we begin the construction of ANN with the above network output as input\n    model.add(Flatten())\n    model.add(Dense(256,activation='relu'))\n    model.add(BatchNormalization(axis=-1))\n    model.add(Dropout(rate=0.25))\n    model.add(Dense(1,activation='softmax'))\n    \n    return model","execution_count":164,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=CNN_neural()","execution_count":165,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=Adam(0.0001), loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":166,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test= train_test_split(dataset,test_size=0.1, shuffle=False,random_state=0)","execution_count":167,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train,y_test= train_test_split(y_true,test_size=0.1,shuffle=False,random_state=0)","execution_count":171,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''X_train=np.array(X_train)\ny_train=np.array(y_train)\n\nX_test=np.array(X_test)\ny_test=np.array(y_test)'''\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=np.resize(X_train, (-1, 64,64))","execution_count":172,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=np.expand_dims(X_train,axis=3)","execution_count":173,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":174,"outputs":[{"output_type":"execute_result","execution_count":174,"data":{"text/plain":"(226, 64, 64, 1)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x=X_train, y=y_train, batch_size=None,epochs=100, verbose=1, callbacks=None, validation_split=0.1,validation_data=None, shuffle=True, steps_per_epoch=202)\n","execution_count":175,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Input arrays should have the same number of samples as target arrays. Found 226 input samples and 227 target samples.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-175-844f819c5561>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m202\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    802\u001b[0m             ]\n\u001b[1;32m    803\u001b[0m             \u001b[0;31m# Check that all arrays have the same length.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0mcheck_array_length_consistency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m                 \u001b[0;31m# Additional checks to avoid users mistakenly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_array_length_consistency\u001b[0;34m(inputs, targets, weights)\u001b[0m\n\u001b[1;32m    235\u001b[0m                          \u001b[0;34m'the same number of samples as target arrays. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                          \u001b[0;34m'Found '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' input samples '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                          'and ' + str(list(set_y)[0]) + ' target samples.')\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_w\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         raise ValueError('All sample_weight arrays should have '\n","\u001b[0;31mValueError\u001b[0m: Input arrays should have the same number of samples as target arrays. Found 226 input samples and 227 target samples."]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(output.history['acc'])\nplt.plot(output.history['val_acc'])\nplt.title('classifier  based accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(output.history['loss'])\nplt.plot(output.history['val_loss'])\nplt.title('classifier based loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}